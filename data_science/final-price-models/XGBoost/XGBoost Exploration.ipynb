{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cc7eef-4b4b-4579-b7b8-8c132ef512ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 17:37:11.767970: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-21 17:37:11.833727: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-21 17:37:11.835226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 17:37:12.804295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # turn off deprecation warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import  mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f94ac36-1d6a-49c9-8a62-bf9eea334460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 80.88625979423523 seconds\n",
      "Mean Squared Error (MSE): 0.00011649733790087549\n",
      "Mean Absolute Error (MAE): 0.008316633596719516\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/latest_hour_final_btc.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Start measuring the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the 'future' column by shifting the 'closing_price' column 10 rows forward\n",
    "df_normalized['future'] = df_normalized['close'].shift(-1)\n",
    "\n",
    "df_normalized = df_normalized.dropna()\n",
    "\n",
    "\n",
    "X = df_normalized.drop(columns='future', axis=1)  # Exclude the target column from features\n",
    "y = df_normalized['future']  # Target column (the one you want to predict)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline([ ('xgbrg', XGBRegressor())   ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [10, 50, 100],\n",
    "    \n",
    "    \"xgbrg__learning_rate\": [0.01, 0.1, 0.5, 1],\n",
    "} \n",
    "\n",
    "\n",
    "searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "searchCV.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# After fitting the GridSearchCV object\n",
    "best_params = searchCV.best_params_\n",
    "\n",
    "# Modify the best_params dictionary to match the correct parameter names\n",
    "best_params = {\n",
    "    'n_estimators': best_params['xgbrg__n_estimators'],\n",
    "    'learning_rate': best_params['xgbrg__learning_rate']\n",
    "}\n",
    "\n",
    "# Create a new instance of the model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# End measuring the execution time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MSE and MAE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aca8ae1-e9ce-4d53-b23a-2357730eadaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 715.4679706096649 seconds\n",
      "Mean Squared Error (MSE): 0.0007725368481799351\n",
      "Mean Absolute Error (MAE): 0.019117578201101826\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/latest_hour_final_btc.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Start measuring the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the 'future' column by shifting the 'closing_price' column 10 rows forward\n",
    "df_normalized['future'] = df_normalized['close'].shift(-3)\n",
    "\n",
    "df_normalized = df_normalized.dropna()\n",
    "\n",
    "\n",
    "X = df_normalized.drop(columns='future', axis=1)  # Exclude the target column from features\n",
    "y = df_normalized['future']  # Target column (the one you want to predict)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline([ ('xgbrg', XGBRegressor())   ])\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [10, 50, 100,  200],\n",
    "    \n",
    "    \"xgbrg__learning_rate\": [0.001,0.01, 0.1, 0.5, 1],\n",
    "} \n",
    "\n",
    "\n",
    "searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "searchCV.fit(X_train, y_train)  \n",
    "\n",
    "# After fitting the GridSearchCV object\n",
    "best_params = searchCV.best_params_\n",
    "\n",
    "# Modify the best_params dictionary to match the correct parameter names\n",
    "best_params = {\n",
    "    'n_estimators': best_params['xgbrg__n_estimators'],\n",
    "    'learning_rate': best_params['xgbrg__learning_rate']\n",
    "}\n",
    "\n",
    "# Create a new instance of the model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# End measuring the execution time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MSE and MAE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdeb40d8-e632-4044-941e-ad7c3a415fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 210.12177991867065 seconds\n",
      "Mean Squared Error (MSE): 0.0007879048958133687\n",
      "Mean Absolute Error (MAE): 0.020796456555588802\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/latest_hour_final_btc.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Start measuring the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the 'future' column by shifting the 'closing_price' column 10 rows forward\n",
    "df_normalized['future'] = df_normalized['close'].shift(-6)\n",
    "\n",
    "df_normalized = df_normalized.dropna()\n",
    "\n",
    "\n",
    "X = df_normalized.drop(columns='future', axis=1)  # Exclude the target column from features\n",
    "y = df_normalized['future']  # Target column (the one you want to predict)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline([ ('xgbrg', XGBRegressor())   ])\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [10, 50, 100,  200],\n",
    "    \n",
    "    \"xgbrg__learning_rate\": [0.001,0.01, 0.1, 0.5, 1],\n",
    "} \n",
    "\n",
    "\n",
    "searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "searchCV.fit(X_train, y_train)  \n",
    "\n",
    "# After fitting the GridSearchCV object\n",
    "best_params = searchCV.best_params_\n",
    "\n",
    "# Modify the best_params dictionary to match the correct parameter names\n",
    "best_params = {\n",
    "    'n_estimators': best_params['xgbrg__n_estimators'],\n",
    "    'learning_rate': best_params['xgbrg__learning_rate']\n",
    "}\n",
    "\n",
    "\n",
    "# Create a new instance of the model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# End measuring the execution time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MSE and MAE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7523efdd-9625-40a6-8fdd-2fd2a692efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 715.634092092514 seconds\n",
      "Mean Squared Error (MSE): 0.0013122094029579695\n",
      "Mean Absolute Error (MAE): 0.026207110374512586\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/latest_hour_final_btc.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Start measuring the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the 'future' column by shifting the 'closing_price' column 10 rows forward\n",
    "df_normalized['future'] = df_normalized['close'].shift(-12)\n",
    "\n",
    "df_normalized = df_normalized.dropna()\n",
    "\n",
    "\n",
    "X = df_normalized.drop(columns='future', axis=1)  # Exclude the target column from features\n",
    "y = df_normalized['future']  # Target column (the one you want to predict)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline([ ('xgbrg', XGBRegressor())   ])\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [10, 50, 100,  200],\n",
    "    \n",
    "    \"xgbrg__learning_rate\": [0.001,0.01, 0.1, 0.5, 1],\n",
    "} \n",
    "\n",
    "searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "searchCV.fit(X_train, y_train)  \n",
    "\n",
    "# After fitting the GridSearchCV object\n",
    "best_params = searchCV.best_params_\n",
    "\n",
    "# Modify the best_params dictionary to match the correct parameter names\n",
    "best_params = {\n",
    "    'n_estimators': best_params['xgbrg__n_estimators'],\n",
    "    'learning_rate': best_params['xgbrg__learning_rate']\n",
    "}\n",
    "\n",
    "# Create a new instance of the model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# End measuring the execution time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MSE and MAE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550f6791-6e96-4cfc-a0af-c97e39fc1c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Elapsed time: 208.05149364471436 seconds\n",
      "Mean Squared Error (MSE): 0.003528178606690366\n",
      "Mean Absolute Error (MAE): 0.04326569163545041\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/latest_hour_final_btc.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Start measuring the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the 'future' column by shifting the 'closing_price' column 10 rows forward\n",
    "df_normalized['future'] = df_normalized['close'].shift(-24)\n",
    "\n",
    "df_normalized = df_normalized.dropna()\n",
    "\n",
    "\n",
    "X = df_normalized.drop(columns='future', axis=1)  # Exclude the target column from features\n",
    "y = df_normalized['future']  # Target column (the one you want to predict)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline([ ('xgbrg', XGBRegressor())   ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [10, 50, 100,  200],\n",
    "    \n",
    "    \"xgbrg__learning_rate\": [0.001,0.01, 0.1, 0.5, 1],\n",
    "} \n",
    "\n",
    "print(1)\n",
    "searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "searchCV.fit(X_train, y_train)  \n",
    "\n",
    "# After fitting the GridSearchCV object\n",
    "best_params = searchCV.best_params_\n",
    "\n",
    "# Modify the best_params dictionary to match the correct parameter names\n",
    "best_params = {\n",
    "    'n_estimators': best_params['xgbrg__n_estimators'],\n",
    "    'learning_rate': best_params['xgbrg__learning_rate']\n",
    "}\n",
    "\n",
    "# Create a new instance of the model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "print(2)\n",
    "\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# End measuring the execution time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MSE and MAE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21daf848-2c12-4a81-a1c3-f0cfce2b721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Elapsed time: 210.5539424419403 seconds\n",
      "Mean Squared Error (MSE): 0.0025622061991426633\n",
      "Mean Absolute Error (MAE): 0.03770257142652256\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/latest_hour_final_btc.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Start measuring the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the 'future' column by shifting the 'closing_price' column 10 rows forward\n",
    "df_normalized['future'] = df_normalized['close'].shift(-27)\n",
    "df_normalized = df_normalized.dropna()\n",
    "\n",
    "\n",
    "X = df_normalized.drop(columns='future', axis=1)  # Exclude the target column from features\n",
    "y = df_normalized['future']  # Target column (the one you want to predict)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline([ ('xgbrg', XGBRegressor())   ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [10, 50, 100,  200],\n",
    "    \n",
    "    \"xgbrg__learning_rate\": [0.001,0.01, 0.1, 0.5, 1],\n",
    "} \n",
    "\n",
    "print(1)\n",
    "searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "searchCV.fit(X_train, y_train)  \n",
    "\n",
    "# After fitting the GridSearchCV object\n",
    "best_params = searchCV.best_params_\n",
    "\n",
    "# Modify the best_params dictionary to match the correct parameter names\n",
    "best_params = {\n",
    "    'n_estimators': best_params['xgbrg__n_estimators'],\n",
    "    'learning_rate': best_params['xgbrg__learning_rate']\n",
    "}\n",
    "\n",
    "# Create a new instance of the model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "print(2)\n",
    "\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# End measuring the execution time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MSE and MAE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff734ec8-c2b9-4586-90e0-7a5538a9db13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
