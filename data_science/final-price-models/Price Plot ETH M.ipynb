{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a420e6-2fb6-4c63-b196-35232f8f492f",
   "metadata": {},
   "source": [
    "# Price Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae73c3c3-3726-4101-b6c0-001d51297f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 17:48:26.352017: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-14 17:48:26.825634: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-14 17:48:26.828744: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 17:48:28.834385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcf204-e2af-4821-8890-f41fd091ec7e",
   "metadata": {},
   "source": [
    "## Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05454cee-a5c4-4e0b-b8d2-94e5ff9ffa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep Data\n",
      "num_train_samples: 411334\n",
      "num_val_samples: 171389\n",
      "num_test_samples: 102835\n",
      "<class 'numpy.ndarray'>\n",
      "(685558, 74)\n",
      "(685558, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data and preprocess it into train, validation, and test sets \n",
    "df = pd.read_csv('../data/latest_minute_final_eth.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','datetime','DATE'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "raw_data = df_normalized.values\n",
    "close = df_normalized['close'].values\n",
    "close = close.reshape((len(close),1))\n",
    "\n",
    "print('Prep Data')\n",
    "num_train_samples = int(0.6 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "print(\"num_train_samples:\", num_train_samples)\n",
    "print(\"num_val_samples:\", num_val_samples)\n",
    "print(\"num_test_samples:\", num_test_samples)\n",
    "\n",
    "\n",
    "# Display the NumPy array\n",
    "print(type(raw_data))\n",
    "print(raw_data.shape)\n",
    "print(close.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71028a2d-83e4-4127-85e0-af3fb323131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The timeseries will consist of batches containing 64 sequences of 288 samples.\n",
      "Finally our target is 60 timesteps in the future, and will have data from 1440 timesteps in the past\n",
      "Done Train\n",
      "Done Validation\n",
      "Done Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 17:48:56.557501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-14 17:48:56.559271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-14 17:48:56.560671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-14 17:48:56.680876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_28' with dtype int32 and shape [169950]\n",
      "\t [[{{node Placeholder/_28}}]]\n",
      "2023-05-14 17:48:56.681446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype int32\n",
      "\t [[{{node Placeholder/_13}}]]\n",
      "2023-05-14 17:48:57.044736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-14 17:48:57.046614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-14 17:48:57.048208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656/2656 [==============================] - 100s 38ms/step\n",
      "   1/1584 [..............................] - ETA: 3:44"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 17:50:38.665895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [102775,74]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-14 17:50:38.666546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [102775,74]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 442/1584 [=======>......................] - ETA: 47s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR)\n\u001b[1;32m     81\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_dataset)\n\u001b[0;32m---> 82\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m val_real \u001b[38;5;241m=\u001b[39m close[num_train_samples:num_train_samples \u001b[38;5;241m+\u001b[39m num_val_samples\u001b[38;5;241m-\u001b[39m (sequence_length \u001b[38;5;241m*\u001b[39m sampling_rate)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     86\u001b[0m test_real \u001b[38;5;241m=\u001b[39m close[num_train_samples \u001b[38;5;241m+\u001b[39m num_val_samples:\u001b[38;5;241m-\u001b[39m(sequence_length \u001b[38;5;241m*\u001b[39m sampling_rate)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/keras/engine/training.py:2382\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2381\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2382\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2384\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_v0/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 5\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length = 6 * 2 * 24\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 64\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_1_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6c9ae-74b1-4b84-875d-d2a930f1c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60 * 3\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 10\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length = 6 * 3 * 24\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 64\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_3_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c5d4d-e435-48e0-a7f3-1d7d4b70c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60 * 6\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 20\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length = 6 * 3 * 24\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 64\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_6_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ca732-dbc2-4261-afb1-0a4376f81591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60 * 12\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 20\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length = 6 * 3 * 24\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 64\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_12_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29ab79-13fe-4495-ad7b-dc1edaac0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60 * 24\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 30\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length = 6 * 3 * 24\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_24_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68527b-c7e8-4d7d-8f24-2e02df286c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60 * 3 * 24\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 30\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length = 6 * 3 * 24\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 64\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_3d_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d33ea-e19a-4874-bd28-b3f9e0a95237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 60 * 24 * 7\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 45\n",
    "\n",
    "# sequence length: sequence lenght of each sample \n",
    "sequence_length =  300\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 1\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 64\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)\n",
    "\n",
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = keras.models.load_model(\"ETH Minute/lstm_model_7d_ahead.h5\")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "val_pred = model.predict(val_dataset)\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "l = len(val_pred)\n",
    "o = -delay\n",
    "val_real= close[num_train_samples+o:num_train_samples + l - delay]\n",
    "test_real = close[num_train_samples + num_val_samples:num_train_samples + num_val_samples +len(test_pred)]\n",
    "#[num_train_samples + num_val_samples:-(sequence_length * sampling_rate)+1+delay]\n",
    "\n",
    "print(len(val_pred) == len(val_real), len(val_pred) , len(val_real), )\n",
    "print(len(test_pred) == len(test_real), len(test_pred) , len(test_real))\n",
    "\n",
    "\n",
    "\n",
    "# Assume 'y_normalized' contains the predicted values for the 'target' column in normalized form\n",
    "y_min = df['close'].min()\n",
    "y_max = df['close'].max()\n",
    "\n",
    "val_real = val_real * (y_max - y_min) + y_min\n",
    "val_pred = val_pred * (y_max - y_min) + y_min\n",
    "\n",
    "test_real = test_real * (y_max - y_min) + y_min\n",
    "test_pred = test_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot a and b in the left-hand subplot\n",
    "ax1.set_title('Validation')\n",
    "ax1.plot(val_real, label='Actual')\n",
    "ax1.plot(val_pred, label='Prediction')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot c and d in the right-hand subplot\n",
    "ax2.set_title('Test')\n",
    "ax2.plot(test_real, label='Actual')\n",
    "ax2.plot(test_pred, label='Prediction')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Price')\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce055f8d-0d8f-47a3-ae73-c39539b55b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
