{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e55b9-97c6-4619-b578-7216310b186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # turn off deprecation warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69bdf13-788a-45ae-9349-855ab869aad6",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27cb5d-3c93-4fc4-8f70-0236832c6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/final_dataset.csv')\n",
    "df.drop(columns=['Unnamed: 0.1','Unnamed: 0','datetime'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dfaab-ca5f-44c9-bd48-3d87d63cb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler on your dataframe (let's say it's called df)\n",
    "df_normalized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a dataframe\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afe18c-7dfc-4da9-9260-e9d44df91dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "raw_data = df_normalized.values\n",
    "close = df_normalized['close'].values\n",
    "close = close.reshape((len(close),1))\n",
    "# Display the NumPy array\n",
    "print(type(raw_data))\n",
    "print(raw_data.shape)\n",
    "print(close.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cff0c-9fe4-45d8-a4dc-96009de11ced",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efe0c9-3bd6-489e-9608-572dce576afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prep Data')\n",
    "num_train_samples = int(0.6 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "print(\"num_train_samples:\", num_train_samples)\n",
    "print(\"num_val_samples:\", num_val_samples)\n",
    "print(\"num_test_samples:\", num_test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43acc9c6-20f6-48a4-9631-dd81768b4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# delay: time in future that will be predicted\n",
    "delay = 24 * 60\n",
    "\n",
    "\n",
    "# sampling rate: period between timesteps within the sequence\n",
    "# Sequence with rate=1 : t1,t2...tn\n",
    "# Sequence with rate=3 : t1,t3...tn*3\n",
    "sampling_rate = 30\n",
    "\n",
    "# sequence length: sequence lenght of each sample\n",
    "half_day = 12 * 60\n",
    "sequence_length = int(14 * half_day / sampling_rate)\n",
    "\n",
    "\n",
    "# sequence_stride: period between sequences\n",
    "# First sequence starts at t0\n",
    "# Second sequence will start at t1 with sequence_stride=1 or at t5 with sequence_stride=5\n",
    "sequence_stride = 10\n",
    "\n",
    "#batch_size: Number of timeseries samples in each batch (except maybe the last one). \n",
    "#If None, the data will not be batched (the dataset will yield individual samples).\n",
    "# Huge impact in performance.\n",
    "# Tip, should be multiple of 8\n",
    "batch_size = 128\n",
    "\n",
    "# Understanding our parameters\n",
    "msg = f\"The timeseries will consist of batches containing {batch_size} sequences of {sequence_length} samples.\"\n",
    "\n",
    "msg += f\"\\nFinally our target is {delay} timesteps in the future, and will have data from {sequence_length * sampling_rate} timesteps in the past\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319e6e4-797a-47f5-b83d-c51e26ae7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                        raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=0,\n",
    "                    end_index=num_train_samples)\n",
    "\n",
    "print(\"Done Train\")\n",
    "\n",
    "val_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Validation\")      \n",
    "\n",
    "test_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=sampling_rate,\n",
    "                    sequence_stride=sequence_stride,\n",
    "                    sequence_length=sequence_length,\n",
    "                    shuffle=False,\n",
    "                    seed=33,\n",
    "                    batch_size=batch_size,\n",
    "                    start_index=num_train_samples + num_val_samples)\n",
    "\n",
    "print(\"Done Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cd9fb-c122-487e-bd9d-8ceee07c1962",
   "metadata": {},
   "source": [
    "# Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb9771-740c-44b4-81d0-9a4cfa6d6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.LSTM(64)(inputs)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/lstm\",\n",
    "   save_best_only=True) \n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=30,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533fdee-3871-4102-a4f4-d21436354799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model.save('lstm_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a03600d-e30a-4b04-be2f-b8c8ae8c8ce4",
   "metadata": {},
   "source": [
    "# Understanding the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce87b11-34f4-41d9-a2a8-3b604de0aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d79e54-e7b0-48cf-82d2-e8fe98d094b5",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f2aeb-45ac-4430-8618-7c82e2169748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "                    raw_data[:-delay],\n",
    "                    targets=close[delay:],\n",
    "                    sampling_rate=1,\n",
    "                    sequence_stride=1,\n",
    "                    sequence_length=180,\n",
    "                    shuffle=False, # Shouldn't the shuffle be set to 0?\n",
    "                    seed=33,\n",
    "                    batch_size=32,\n",
    "                    start_index=num_train_samples,\n",
    "                    end_index=num_train_samples + num_val_samples\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039bd51-968f-471c-a681-7737073553fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions = model.predict(pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99810d71-b34c-401f-a2ab-fd3b9fbf60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions) )\n",
    "print(len(close[:660745]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc603f3-68d5-43bf-b302-7ad74afbefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions using your model and store it in a variable called 'predictions'\n",
    "\n",
    "# Plot the actual data\n",
    "plt.plot(range(len(predictions)), close[num_train_samples+180:num_train_samples + num_val_samples+1], label='Actual Data')\n",
    "\n",
    "# Plot the predicted data\n",
    "plt.plot(range(len(predictions)), predictions, label='Predicted Data')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "plt.title('Actual vs Predicted Data')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98bd81-2d63-4561-91ff-c664038a5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(len(close)), close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e4a2f-0b69-40be-9010-6f3b82e1c0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
