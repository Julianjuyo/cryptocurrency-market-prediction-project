{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "PROXIES = {\n",
    "    \n",
    "   'http': 'http://discproxy.virtual.uniandes.edu.co:443',\n",
    "}\n",
    "\n",
    "EXCHANGE_ID = \"2eccdb22-ec97-4799-9755-77c976991af8\"\n",
    "\n",
    "# BTCUSDT_DAY_ID = \"81d625dd-f73f-4829-a2ff-1d795fbc5b3a\"\n",
    "# BTCUSDT_HOUR_ID = \"7aa396ec-8c6a-44fd-89f2-12e7f998f883\"\n",
    "# BTCUSDT_MINUTE_ID = \"31deee63-e4bb-45ad-b020-8759b5c69e0f\"\n",
    "\n",
    "\n",
    "# ETHUSDT_DAY_ID = \"67da12e9-6fd9-4401-b16a-1c2dd589ff01\"\n",
    "# ETHUSDT_HOUR_ID = \"35515212-5467-45b4-b2e5-3ae048e482e7\"\n",
    "# ETHUSDT_MINUTE_ID = \"38d4f96b-26b7-420a-a34f-912f5ad23eaf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to make a POST request to the specified API endpoint with a JSON payload\n",
    "def post_method(url_path, data_dict):\n",
    "    print(\"POST request to: \" + url_path)\n",
    "    # Convert the dictionary to a JSON string using the `json` module\n",
    "    json_payload = json.dumps(data_dict)\n",
    "\n",
    "    print(json_payload)\n",
    "    # try:\n",
    "    # Send the POST request with the JSON payload\n",
    "    response = requests.post(url_path, data=json_payload, proxies=PROXIES)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == requests.codes.created:\n",
    "        # If successful, print the response content and convert it to a Pandas DataFrame\n",
    "        print(\"created post status code: \" + str(response.status_code))\n",
    "\n",
    "        print(response.content)\n",
    "        json_data = json.loads(response.content)\n",
    "        df = pd.json_normalize(json_data)\n",
    "        return df\n",
    "    else:\n",
    "        # If unsuccessful, print the response content\n",
    "        print(\"post status code: \"+str(response.status_code))\n",
    "        print(response.content)\n",
    "\n",
    "def create_exchange(base_url, data_dict):\n",
    "    # Call the `post_method` function with the appropriate URL and data dictionary\n",
    "    print(\"Endpoint: \" + base_url + \"exchanges\")\n",
    "    resp = post_method(base_url + \"exchanges\", data_dict)\n",
    "    return resp\n",
    "# post_method(base_url + \"exchanges\", data_dict)\n",
    "    \n",
    "def create_asset(base_url,exchange_id, data_dict):\n",
    "    # Call the `post_method` function with the appropriate URL and data dictionary\n",
    "    print(\"Endpoint: \" + base_url + \"assets\")\n",
    "    resp = post_method(base_url + \"exchanges/\"+exchange_id+\"/asset\", data_dict)\n",
    "    return resp\n",
    "# post_method(base_url + \"exchanges\", data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://172.24.100.128:5000/\"\n",
    "# base_url = \"http://localhost:5000/\"\n",
    "\n",
    "dict =  {\n",
    "    \"symbol\": \"ETHUSDT\",\n",
    "    \"base_asset\": \"ETH\",\n",
    "    \"quote_asset\": \"USDT\",\n",
    "    \"interval\": \"day\",\n",
    "    \"asset_type\": \"Cryptocurrency\"\n",
    "  }\n",
    "\n",
    "data ={\n",
    "    \"name\": \"binance\"\n",
    "}\n",
    "\n",
    "\n",
    "# a = create_exchange(base_url,data)\n",
    "\n",
    "\n",
    "a = create_asset(base_url,EXCHANGE_ID,dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import ta\n",
    "import math\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "BINANCE_URL = 'https://api.binance.com/api/v3/klines'\n",
    "\n",
    "NUM_CORES = 4\n",
    "\n",
    "PROXIES = {    \n",
    "   'http': 'http://discproxy.virtual.uniandes.edu.co:443',\n",
    "}\n",
    "\n",
    "# Method to make API request to retrieve the last recorded price timestamp for a given asset ID\n",
    "\n",
    "\n",
    "def api_request_last_time_stamp_from_asset_id(base_url, asset_id):\n",
    "    # try:\n",
    "    print(\"entro api_request_last_time_stamp_from_asset_id\")\n",
    "\n",
    "    # Make GET request to API endpoint\n",
    "    response = requests.get(base_url + \"assets/\" + asset_id + \"/last_price/\")#,proxies= PROXIES)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == requests.codes.ok:\n",
    "\n",
    "        print(\"get las unix time status code: \"+str(response.status_code))\n",
    "\n",
    "        # Convert JSON response to Python dictionary\n",
    "        json_data = json.loads(response.content)\n",
    "        # Normalize the dictionary and convert it to a Pandas DataFrame\n",
    "        df = pd.json_normalize(json_data)\n",
    "        # Return the Unix timestamp of the last recorded price for the specified asset ID\n",
    "        return int(df['unix_time'].iloc[0])\n",
    "    else:\n",
    "        print(\"fallo\")\n",
    "        print(response.content)\n",
    "        json_data = json.loads(response.content)\n",
    "        df = pd.json_normalize(json_data)\n",
    "        return df\n",
    "    # except:\n",
    "    #     print(\"Failed api_request_last_time_stamp_from_asset_id\")\n",
    "\n",
    "# Method to make a GET request to the API endpoint\n",
    "\n",
    "\n",
    "def api_request_get_asset_from_asset_id(base_url, exchange_id, asset_id):\n",
    "    # try:\n",
    "    # Make GET request to API endpoint\n",
    "\n",
    "    response = requests.get(base_url + \"exchanges/\" +\n",
    "                            exchange_id + \"/asset/\"+asset_id)#,proxies=PROXIES)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        print(\"get asset status code: \"+str(response.status_code))\n",
    "        # Convert JSON response to Python dictionary\n",
    "        json_data = json.loads(response.content)\n",
    "        # Normalize the dictionary and convert it to a Pandas DataFrame\n",
    "        df = pd.json_normalize(json_data)\n",
    "        # Return the Unix timestamp of the last recorded price for the specified asset ID\n",
    "\n",
    "        print(\"symbol: \" + df[\"symbol\"].iloc[0])\n",
    "        print(\"interval: \" + df[\"interval\"].iloc[0])\n",
    "        return df\n",
    "    else:\n",
    "        print(response.content)\n",
    "        json_data = json.loads(response.content)\n",
    "        df = pd.json_normalize(json_data)\n",
    "        return df\n",
    "    # except:\n",
    "    #     print(\"Failed api_request_get_asset_from_asset_id\")\n",
    "\n",
    "\n",
    "# Method to make API request to retrieve prices for a given asset ID between two specified Unix timestamps\n",
    "def api_request_get_prices_between_unix_time(base_url, asset_id, unix_time_start, unix_time_end):\n",
    "\n",
    "    print(\"entro api_request_get_prices_between_unix_time\")\n",
    "\n",
    "    # try:\n",
    "    # Make GET request to API endpoint with query parameters for start and end Unix timestamps\n",
    "    response = requests.get(base_url + \"assets/\" + asset_id + \"/indicators_unix_between/\",\n",
    "                            params={'unix_time_start': unix_time_start, 'unix_time_end': unix_time_end})#,proxies= PROXIES)\n",
    "\n",
    "    print(\"status code time between: \" + str(response.status_code))\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        print(\"get prices between status code: \"+str(response.status_code))\n",
    "        # Convert JSON response to Python dictionary\n",
    "        json_data = json.loads(response.content)\n",
    "        # Normalize the dictionary and convert it to a Pandas DataFrame\n",
    "        df = pd.json_normalize(json_data)\n",
    "        # Return the DataFrame containing the retrieved price data\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        print(\"Failed api_request_get_prices_between_unix_time\")\n",
    "        json_data = json.loads(response.content)\n",
    "\n",
    "        print(json_data)\n",
    "        return json_data\n",
    "\n",
    "    # except:\n",
    "    #     print(\"Failed api_request_get_prices_between_unix_time\")\n",
    "\n",
    "\n",
    "# Method to make a POST request to the specified API endpoint with a JSON payload\n",
    "def post_method(url_path, data_dict):\n",
    "    # Convert the dictionary to a JSON string using the `json` module\n",
    "    json_payload = json.dumps(data_dict)\n",
    "    # print(\"data : \"+json_payload)\n",
    "\n",
    "    # try:\n",
    "    # Send the POST request with the JSON payload\n",
    "    response = requests.post(url_path, data=json_payload)#,proxies= PROXIES)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == requests.codes.created:\n",
    "        # If successful, print the response content and convert it to a Pandas DataFrame\n",
    "        # print(\"post status code: \" + str(response.status_code))\n",
    "\n",
    "        # print(response.content)\n",
    "        json_data = json.loads(response.content)\n",
    "        df = pd.json_normalize(json_data)\n",
    "        return df\n",
    "    else:\n",
    "        # If unsuccessful, print the response content\n",
    "        print(\"post status code: \"+str(response.status_code))\n",
    "        print(\"failed: \"+json_payload)\n",
    "        print(response.content)\n",
    "\n",
    "    # except:\n",
    "    #     # If an exception occurs, print an error message\n",
    "    #     print(\"Failed to make request\")\n",
    "\n",
    "# Method to create a new price for a given asset ID\n",
    "\n",
    "\n",
    "def create_price_to_asset_id(base_url, asset_id, data_dict):\n",
    "    # Call the `post_method` function with the appropriate URL and data dictionary\n",
    "    return post_method(base_url + \"assets/\" + asset_id + \"/prices/\", data_dict)\n",
    "\n",
    "# Method to create a new indicator for a given price ID\n",
    "\n",
    "\n",
    "def create_indicator_to_price_id(base_url, data_dict):\n",
    "\n",
    "    price_id = data_dict['id']\n",
    "    del data_dict['id']\n",
    "    \n",
    "    # Iterate over the keys of the dictionary\n",
    "    for key in list(data_dict.keys()):\n",
    "        # Check if the value of the key is NaN\n",
    "        if math.isnan(data_dict[key]):\n",
    "            # Delete the key-value pair from the dictionary\n",
    "            del data_dict[key]\n",
    "\n",
    "    # Call the `post_method` function with the appropriate URL and data dictionary\n",
    "    return post_method(base_url + \"prices/\" + price_id + \"/indicators/\", data_dict)\n",
    "\n",
    "\n",
    "def round_minute(epoch_timestamp):\n",
    "    # convert epoch timestamp to datetime object\n",
    "    timestamp1 = datetime.utcfromtimestamp(epoch_timestamp)\n",
    "\n",
    "    # round to nearest day\n",
    "    rounded_timestamp1 = timestamp1.replace(\n",
    "        second=0, microsecond=0, tzinfo=timezone.utc)\n",
    "\n",
    "    # convert rounded timestamp back to epoch timestamp\n",
    "    return int(rounded_timestamp1.timestamp())\n",
    "\n",
    "\n",
    "def round_hour(epoch_timestamp):\n",
    "    # convert epoch timestamp to datetime object\n",
    "    timestamp2 = datetime.utcfromtimestamp(epoch_timestamp)\n",
    "\n",
    "    # round to nearest hour\n",
    "    rounded_timestamp2 = timestamp2.replace(\n",
    "        minute=0, second=0, microsecond=0, tzinfo=timezone.utc)\n",
    "\n",
    "    # convert rounded timestamp back to epoch timestamp\n",
    "    return int(rounded_timestamp2.timestamp())\n",
    "\n",
    "\n",
    "def round_day(epoch_timestamp):\n",
    "    # convert epoch timestamp to datetime object\n",
    "    timestamp3 = datetime.utcfromtimestamp(epoch_timestamp)\n",
    "\n",
    "    # round to nearest day\n",
    "    rounded_timestamp3 = timestamp3.replace(\n",
    "        hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc)\n",
    "\n",
    "    # convert rounded timestamp back to epoch timestamp\n",
    "    return int(rounded_timestamp3.timestamp())\n",
    "\n",
    "\n",
    "def get_data_from_api(\n",
    "        symbol: str, interval: str, initial_timestamp: int, limit_timestamp: int):\n",
    "    \"\"\" This function get the information from binance API\n",
    "    \"\"\"\n",
    "\n",
    "    # Set working dates ------------------------------------------------------------------------------------\n",
    "    # End of Looping Period Date\n",
    "    # Load will go from initial_date to limit_date\n",
    "    # Start date is inclusive\n",
    "\n",
    "    # set fields\n",
    "    fields = ['datetime', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
    "              'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol', 'ignore']\n",
    "\n",
    "    counter = 0\n",
    "    df_prices = pd.DataFrame(columns=fields)\n",
    "\n",
    "    if interval == \"minute\":\n",
    "\n",
    "        initial_timestamp = round_minute(initial_timestamp)\n",
    "        limit_timestamp = round_minute(limit_timestamp)\n",
    "\n",
    "        print(\"last time in the api: \" +\n",
    "              str(datetime.utcfromtimestamp(initial_timestamp)))\n",
    "        print(\"Actual datetime: \" + str(datetime.utcfromtimestamp(limit_timestamp)))\n",
    "\n",
    "        if initial_timestamp + 60 < limit_timestamp:\n",
    "            print(\"Si se trae data\")\n",
    "            initial_timestamp = initial_timestamp + 60\n",
    "            limit_timestamp = limit_timestamp - 62\n",
    "        else:\n",
    "            print(\"Finalizo y no hay datos\")\n",
    "            return df_prices\n",
    "\n",
    "        interval_binance = \"1m\"\n",
    "        limit_binance = \"960\"\n",
    "        following_period = 57600\n",
    "\n",
    "        # We will work with time intervals of 16 hours when working with minutes to have 960 records per API call - LIMIT = 1000\n",
    "        end_date_timestamp = initial_timestamp + following_period\n",
    "\n",
    "    if interval == \"hour\":\n",
    "\n",
    "        initial_timestamp = round_hour(initial_timestamp)\n",
    "        limit_timestamp = round_hour(limit_timestamp)\n",
    "\n",
    "        print(\"last time in the api: \" +\n",
    "              str(datetime.utcfromtimestamp(initial_timestamp)))\n",
    "        print(\"Actual datetime: \" + str(datetime.utcfromtimestamp(limit_timestamp)))\n",
    "\n",
    "        if initial_timestamp + 3600 < limit_timestamp:\n",
    "            print(\"Si se trae data\")\n",
    "            initial_timestamp = initial_timestamp + 3600\n",
    "            limit_timestamp = limit_timestamp - 3602\n",
    "        else:\n",
    "            print(\"Finalizo y no hay datos\")\n",
    "            return df_prices\n",
    "\n",
    "        interval_binance = \"1h\"\n",
    "        limit_binance = \"960\"\n",
    "        following_period = 144000\n",
    "\n",
    "        # We will work with time intervals of 40 days when working with hours to have 960 records per API call - LIMIT = 1000\n",
    "        end_date_timestamp = initial_timestamp + following_period\n",
    "\n",
    "    if interval == \"day\":\n",
    "\n",
    "        initial_timestamp = round_day(initial_timestamp)\n",
    "        limit_timestamp = round_day(limit_timestamp)\n",
    "\n",
    "        print(\"last time in the api: \" +\n",
    "              str(datetime.utcfromtimestamp(initial_timestamp)))\n",
    "        print(\"Actual datetime: \" + str(datetime.utcfromtimestamp(limit_timestamp)))\n",
    "\n",
    "        if initial_timestamp + 86400 < limit_timestamp:\n",
    "            print(\"Si se trae data\")\n",
    "            initial_timestamp = initial_timestamp + 86400\n",
    "            limit_timestamp = limit_timestamp - 86402\n",
    "        else:\n",
    "            print(\"Finalizo y no hay datos\")\n",
    "            return df_prices\n",
    "\n",
    "        interval_binance = \"1d\"\n",
    "        limit_binance = \"360\"\n",
    "        following_period = 31104000\n",
    "        end_date_timestamp = initial_timestamp + following_period\n",
    "\n",
    "    # Start time of function\n",
    "    loop_start_time = datetime.now()\n",
    "\n",
    "    # Loop through API calls ---------------------------------------------------------------------------\n",
    "    while initial_timestamp < limit_timestamp:\n",
    "        print(\"Entro loop\")\n",
    "\n",
    "        # Set dates to Binance API format\n",
    "        start = str(initial_timestamp*1000)\n",
    "\n",
    "        if end_date_timestamp > limit_timestamp:\n",
    "            end = str(limit_timestamp*1000)\n",
    "        else:\n",
    "            end = str(end_date_timestamp*1000)\n",
    "\n",
    "        par = {'symbol': symbol, 'interval': interval_binance,\n",
    "               'startTime': start, 'endTime': end, 'limit': limit_binance}\n",
    "\n",
    "        # API CALL\n",
    "        response = requests.get(BINANCE_URL, params=par)\n",
    "        json_data = json.loads(response.content)\n",
    "        new_df = pd.DataFrame(json_data, columns=fields)\n",
    "        df_prices = pd.concat([df_prices, new_df], axis=0)\n",
    "\n",
    "        # Move to following period\n",
    "        initial_timestamp = end_date_timestamp\n",
    "        end_date_timestamp = initial_timestamp + following_period\n",
    "        counter += 1\n",
    "\n",
    "    # End time of function\n",
    "    loop_end_time = datetime.now()\n",
    "\n",
    "    time = loop_end_time - loop_start_time\n",
    "\n",
    "    print('DONE', '\\nDURATION:', time.days, 'DAYS', time.seconds//3600, 'HOURS',\n",
    "          (time.seconds//60) % 60, 'MINUTES', time.seconds % 60, 'SECONDS.')\n",
    "    print('API CALLS:', counter, ' ROWS:', len(df_prices))\n",
    "\n",
    "    df_prices = df_prices.rename(columns={'datetime': 'unix_time',\n",
    "                                          'open': 'open_price',\n",
    "                                          'high': 'high_price',\n",
    "                                          'low': 'low_price',\n",
    "                                          'close': 'close_price'})\n",
    "\n",
    "    df_prices['unix_time'] = df_prices['unix_time'].apply(\n",
    "        lambda x: int(round(x / 1000)))\n",
    "\n",
    "    return df_prices\n",
    "\n",
    "\n",
    "def get_last_timestamp(base_url, asset_id, interval):\n",
    "\n",
    "    last_timestamp_response = api_request_last_time_stamp_from_asset_id(\n",
    "        base_url, asset_id)\n",
    "\n",
    "    last_timestamp = None\n",
    "    first_report = None\n",
    "\n",
    "    if isinstance(last_timestamp_response, int):\n",
    "        first_report = False\n",
    "        last_timestamp = last_timestamp_response\n",
    "    else:\n",
    "        if last_timestamp_response[\"error message\"].iloc[0] == \"There are not prices for this asset\":\n",
    "            print(\"There are not prices for this asset\")\n",
    "\n",
    "            first_report = True\n",
    "\n",
    "            if interval == \"minute\":\n",
    "                last_timestamp = 1638230400  # 30 of november 2021\n",
    "            if interval == \"hour\":\n",
    "                last_timestamp = 1638230400  # 30 of november 2021\n",
    "            if interval == \"day\":\n",
    "                last_timestamp = 1630368000  # 31 of august 2021\n",
    "\n",
    "        elif last_timestamp_response[\"error message\"].iloc[0] == \"The Asset with the given id was not found\":\n",
    "            print(\"The Asset with the given id was not found\")\n",
    "            last_timestamp = None\n",
    "\n",
    "    return last_timestamp, first_report\n",
    "\n",
    "\n",
    "def upload_prices(df_prices, base_url, asset_id):\n",
    "\n",
    "    if df_prices.empty:\n",
    "        print(\"There are NO prices to upload\")\n",
    "    else:\n",
    "        print(\"There are prices to upload\")\n",
    "\n",
    "        # make multiple POST requests in parallel using joblib\n",
    "        num_cores = NUM_CORES  # number of CPU cores to use\n",
    "        data_list = df_prices.to_dict('records')  # convert dataframe to list of dictionaries\n",
    "        results = Parallel(n_jobs=num_cores)(delayed(create_price_to_asset_id)(base_url, asset_id,data) for data in data_list)\n",
    "\n",
    "\n",
    "    print(\"DONE upload_prices\")\n",
    "\n",
    "\n",
    "# Define a function to convert Unix timestamp to date string\n",
    "# def unix_to_date(unix_timestamp):\n",
    "#     datetime_obj = datetime.utcfromtimestamp(unix_timestamp)\n",
    "#     date_str = datetime_obj.date().strftime('%Y-%m-%d')\n",
    "#     return date_str\n",
    "\n",
    "\n",
    "# Method to get\n",
    "def get_full_prices_past(base_url, asset_id, interval, last_timestamp, first_report, final_timestamp):\n",
    "\n",
    "\n",
    "    if first_report:\n",
    "        print(\"first report\")\n",
    "        first_indicator_time = last_timestamp\n",
    "        timestamp_to_add = last_timestamp\n",
    "\n",
    "    else:\n",
    "        if interval == \"minute\":\n",
    "            first_indicator_time = last_timestamp - 6000\n",
    "            timestamp_to_add = last_timestamp - 60\n",
    "\n",
    "        if interval == \"hour\":\n",
    "            first_indicator_time = last_timestamp - 360000\n",
    "            timestamp_to_add = last_timestamp - 3600\n",
    "        if interval == \"day\":\n",
    "            first_indicator_time = last_timestamp - 8640000\n",
    "            timestamp_to_add = last_timestamp - 86400\n",
    "\n",
    "    df_prices = api_request_get_prices_between_unix_time(\n",
    "        base_url, asset_id, first_indicator_time, final_timestamp)\n",
    "\n",
    "    df_prices_wit_indicators = df_prices #add_indicators(df_prices)\n",
    "\n",
    "    df_prices_wit_indicators.drop(['low_price', 'asset_id', 'updated_at', 'high_price', 'volume', 'date_time_utc', 'qav', 'date_time_gmt_5',\n",
    "                                  'num_trades', 'open_price', 'taker_base_vol', 'close_price', 'taker_quote_vol', 'created_at', 'ignore'], axis=1, inplace=True)\n",
    "\n",
    "    df_prices_wit_indicators = df_prices_wit_indicators.loc[\n",
    "        df_prices_wit_indicators['unix_time'] >= timestamp_to_add]\n",
    "\n",
    "    # Apply the function to the 'unix_timestamp' column and create a new column called 'date'\n",
    "    df_prices_wit_indicators['timestamp_round_day'] = df_prices_wit_indicators['unix_time'].apply(\n",
    "        round_day)\n",
    "\n",
    "    return df_prices_wit_indicators\n",
    "\n",
    "\n",
    "# Method to post the indicators to the API\n",
    "def upload_indicators(df_with_indicators, base_url):\n",
    "\n",
    "    print(\"uploading indicators\")\n",
    "\n",
    "    # loop through all rows and convert each row to a JSON object\n",
    "\n",
    "    num_cores = NUM_CORES  # number of CPU cores to use\n",
    "    data_list = df_with_indicators.to_dict('records')  # convert dataframe to list of dictionaries\n",
    "\n",
    "    results = Parallel(n_jobs=num_cores)(delayed(create_indicator_to_price_id)(base_url,data) for data in data_list)\n",
    "    \n",
    "\n",
    "\n",
    "def get_extra_assets_data(start_date, end_date, name, ticker):\n",
    "\n",
    "    print(\"Getting data for: \" + name + \" \"+ticker)\n",
    "\n",
    "    df = yf.Ticker(ticker).history(\n",
    "        interval=\"1d\", start=start_date, end=end_date)\n",
    "    df = df.reset_index(drop=False)\n",
    "\n",
    "    # df['date']= df['Date'].dt.date\n",
    "\n",
    "    df['unix_time'] = df['Date'].dt.date.apply(\n",
    "        lambda x: int(pd.Timestamp(x).timestamp()))\n",
    "\n",
    "    # Apply the function to the 'unix_timestamp' column and create a new column called 'date'\n",
    "    df['timestamp_round_day'] = df['unix_time'].apply(round_day)\n",
    "\n",
    "    df.drop(['Open', 'High', 'Low', 'Volume', 'Dividends',\n",
    "            'Stock Splits', 'Date','unix_time'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    df.rename(columns={'Close': name}, inplace=True)\n",
    "\n",
    "    print(\"DONE getting data for\" + name + \" \"+ticker)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_df_extra_assets_data(start_date, end_date):\n",
    "\n",
    "    dict_assets_extra = {\n",
    "        \"gold_price\":  \"GC=F\",\n",
    "        \"silver_price\":  \"SI=F\",\n",
    "        \"natural_gas_price\":  \"NG=F\",\n",
    "        \"cotton_price\":  \"CT=F\",\n",
    "        \"coffee_price\":  \"KC=F\",\n",
    "        \"sugar_price\":  \"SB=F\",\n",
    "        \"cocoa_price\":  \"CC=F\",\n",
    "        \"rice_price\":  \"ZR=F\",\n",
    "        \"corn_price\":  \"ZC=F\",\n",
    "        \"wheat_price\":  \"KE=F\",\n",
    "        \"soybean_price\":  \"ZS=F\",\n",
    "        \"oats_price\":  \"ZO=F\",\n",
    "        \"spy500_price\":  \"ES=F\",\n",
    "        \"dow_jones_price\":  \"YM=F\",\n",
    "        \"nasdaq_price\":  \"NQ=F\",\n",
    "        \"russell_2000_price\":  \"RTY=F\",\n",
    "        \"us_10_year_treasury_price\":  \"ZN=F\",\n",
    "        \"us_5_year_treasury_price\":  \"ZF=F\",\n",
    "        \"us_2_year_treasury_price\":  \"ZT=F\",\n",
    "        \"usbond_price\":  \"ZB=F\"\n",
    "    }\n",
    "\n",
    "\n",
    "    df_extra_assets_data = pd.DataFrame()\n",
    "    count = 0\n",
    "\n",
    "    for key, value in dict_assets_extra.items():\n",
    "\n",
    "        if count == 0:\n",
    "            df_extra_assets_data = get_extra_assets_data(\n",
    "                start_date, end_date, name=key, ticker=value)\n",
    "\n",
    "        else:\n",
    "            df_extra_assets_data = pd.merge(df_extra_assets_data, get_extra_assets_data(\n",
    "                start_date, end_date, name=key, ticker=value), on='timestamp_round_day', how='outer')\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "    return df_extra_assets_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# from utils import *\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "EXCHANGE_ID = \"2eccdb22-ec97-4799-9755-77c976991af8\"\n",
    "BTCUSDT_DAY_ID = \"2b043a89-de72-4920-a375-fb5991ac405e\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get asset status code: 200\n",
      "symbol: BTCUSDT\n",
      "interval: day\n",
      "entro api_request_last_time_stamp_from_asset_id\n",
      "get las unix time status code: 200\n",
      "last time in the api: 2023-04-22 00:00:00\n",
      "Actual datetime: 2023-04-24 00:00:00\n",
      "Si se trae data\n",
      "DONE \n",
      "DURATION: 0 DAYS 0 HOURS 0 MINUTES 0 SECONDS.\n",
      "API CALLS: 0  ROWS: 0\n",
      "There are NO prices to upload\n",
      "DONE upload_prices\n",
      "entro api_request_get_prices_between_unix_time\n",
      "status code time between: 200\n",
      "get prices between status code: 200\n",
      "Getting data for: gold_price GC=F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zx/38jw3fc56ds6g8b0058y451h0000gn/T/ipykernel_88768/1229164588.py:428: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_prices_wit_indicators['timestamp_round_day'] = df_prices_wit_indicators['unix_time'].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE getting data forgold_price GC=F\n",
      "Getting data for: silver_price SI=F\n",
      "DONE getting data forsilver_price SI=F\n",
      "Getting data for: natural_gas_price NG=F\n",
      "DONE getting data fornatural_gas_price NG=F\n",
      "Getting data for: cotton_price CT=F\n",
      "DONE getting data forcotton_price CT=F\n",
      "Getting data for: coffee_price KC=F\n",
      "DONE getting data forcoffee_price KC=F\n",
      "Getting data for: sugar_price SB=F\n",
      "DONE getting data forsugar_price SB=F\n",
      "Getting data for: cocoa_price CC=F\n",
      "DONE getting data forcocoa_price CC=F\n",
      "Getting data for: rice_price ZR=F\n",
      "DONE getting data forrice_price ZR=F\n",
      "Getting data for: corn_price ZC=F\n",
      "DONE getting data forcorn_price ZC=F\n",
      "Getting data for: wheat_price KE=F\n",
      "DONE getting data forwheat_price KE=F\n",
      "Getting data for: soybean_price ZS=F\n",
      "DONE getting data forsoybean_price ZS=F\n",
      "Getting data for: oats_price ZO=F\n",
      "DONE getting data foroats_price ZO=F\n",
      "Getting data for: spy500_price ES=F\n",
      "DONE getting data forspy500_price ES=F\n",
      "Getting data for: dow_jones_price YM=F\n",
      "DONE getting data fordow_jones_price YM=F\n",
      "Getting data for: nasdaq_price NQ=F\n",
      "DONE getting data fornasdaq_price NQ=F\n",
      "Getting data for: russell_2000_price RTY=F\n",
      "DONE getting data forrussell_2000_price RTY=F\n",
      "Getting data for: us_10_year_treasury_price ZN=F\n",
      "DONE getting data forus_10_year_treasury_price ZN=F\n",
      "Getting data for: us_5_year_treasury_price ZF=F\n",
      "DONE getting data forus_5_year_treasury_price ZF=F\n",
      "Getting data for: us_2_year_treasury_price ZT=F\n",
      "DONE getting data forus_2_year_treasury_price ZT=F\n",
      "Getting data for: usbond_price ZB=F\n",
      "DONE getting data forusbond_price ZB=F\n",
      "uploading indicators\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "base_url = \"http://localhost:5000/\"\n",
    "ASSET_ID = BTCUSDT_DAY_ID\n",
    "\n",
    "\n",
    "final_timestamp = int(datetime.now().timestamp())\n",
    "\n",
    "# Get the asset from the API\n",
    "asset = api_request_get_asset_from_asset_id(base_url,EXCHANGE_ID,ASSET_ID)\n",
    "\n",
    "\n",
    "# Get the last recorded price timestamp for the specified asset ID\n",
    "last_timestamp , first_report  = get_last_timestamp(base_url,ASSET_ID,asset[\"interval\"].iloc[0])\n",
    "\n",
    "# Get the prices from the BINANCE API\n",
    "df_prices_final = get_data_from_api(symbol=asset[\"symbol\"].iloc[0], interval=asset[\"interval\"].iloc[0], initial_timestamp=last_timestamp, limit_timestamp=final_timestamp)\n",
    "\n",
    "#Upload the prices to the API\n",
    "upload_prices(df_prices_final,base_url,ASSET_ID)\n",
    "\n",
    "df_with_indicators = get_full_prices_past( base_url, ASSET_ID, asset[\"interval\"].iloc[0], last_timestamp, first_report,final_timestamp)\n",
    "\n",
    "df_extra_assets_data = create_df_extra_assets_data(start_date=last_timestamp, end_date=final_timestamp)\n",
    "\n",
    "df_final = pd.merge(df_with_indicators, df_extra_assets_data , on='timestamp_round_day', how='left')\n",
    "\n",
    "df_final.drop(['timestamp_round_day'], axis=1, inplace=True)\n",
    "\n",
    "upload_indicators(df_final,base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>silver_price</th>\n",
       "      <th>natural_gas_price</th>\n",
       "      <th>cotton_price</th>\n",
       "      <th>coffee_price</th>\n",
       "      <th>sugar_price</th>\n",
       "      <th>cocoa_price</th>\n",
       "      <th>rice_price</th>\n",
       "      <th>corn_price</th>\n",
       "      <th>wheat_price</th>\n",
       "      <th>soybean_price</th>\n",
       "      <th>oats_price</th>\n",
       "      <th>spy500_price</th>\n",
       "      <th>dow_jones_price</th>\n",
       "      <th>nasdaq_price</th>\n",
       "      <th>russell_2000_price</th>\n",
       "      <th>us_10_year_treasury_price</th>\n",
       "      <th>us_5_year_treasury_price</th>\n",
       "      <th>us_2_year_treasury_price</th>\n",
       "      <th>usbond_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4eff72d3-fe91-4926-afb7-cb5cd71ff186</td>\n",
       "      <td>1682035200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.550003</td>\n",
       "      <td>24.32</td>\n",
       "      <td>2981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f8372f8-9ed7-4edb-9829-0c379fa2832c</td>\n",
       "      <td>1682121600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   unix_time  gold_price   \\\n",
       "0  4eff72d3-fe91-4926-afb7-cb5cd71ff186  1682035200          NaN   \n",
       "1  5f8372f8-9ed7-4edb-9829-0c379fa2832c  1682121600          NaN   \n",
       "\n",
       "   silver_price   natural_gas_price   cotton_price   coffee_price   \\\n",
       "0            NaN                 NaN            NaN     191.550003   \n",
       "1            NaN                 NaN            NaN            NaN   \n",
       "\n",
       "   sugar_price   cocoa_price   rice_price   corn_price   wheat_price   \\\n",
       "0         24.32        2981.0          NaN          NaN           NaN   \n",
       "1           NaN           NaN          NaN          NaN           NaN   \n",
       "\n",
       "   soybean_price   oats_price   spy500_price   dow_jones_price   \\\n",
       "0             NaN          NaN            NaN               NaN   \n",
       "1             NaN          NaN            NaN               NaN   \n",
       "\n",
       "   nasdaq_price   russell_2000_price   us_10_year_treasury_price   \\\n",
       "0            NaN                  NaN                         NaN   \n",
       "1            NaN                  NaN                         NaN   \n",
       "\n",
       "   us_5_year_treasury_price   us_2_year_treasury_price   usbond_price   \n",
       "0                        NaN                        NaN            NaN  \n",
       "1                        NaN                        NaN            NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
